{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc80a93-6dd2-4150-8872-2f13eedf7c68",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+200B (3588180998.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 18\u001b[1;36m\u001b[0m\n\u001b[1;33m    ​\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+200B\n"
     ]
    }
   ],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# List of NFL teams\n",
    "teams = ['arizona-cardinals', 'atlanta-falcons', 'baltimore-ravens', \n",
    "         'buffalo-bills', 'carolina-panthers', 'chicago-bears', \n",
    "         'cincinnati-bengals', 'cleveland-browns', 'dallas-cowboys', \n",
    "         'denver-broncos', 'detroit-lions', 'green-bay-packers', \n",
    "         'houston-texans', 'indianapolis-colts', 'jacksonville-jaguars', \n",
    "         'kansas-city-chiefs', 'las-vegas-raiders', 'los-angeles-chargers', \n",
    "         'los-angeles-rams', 'miami-dolphins', 'minnesota-vikings', \n",
    "         'new-england-patriots', 'new-orleans-saints', 'new-york-giants', \n",
    "         'new-york-jets', 'philadelphia-eagles', 'pittsburgh-steelers', \n",
    "         'san-francisco-49ers', 'seattle-seahawks', 'tampa-bay-buccaneers', \n",
    "         'tennessee-titans', 'washington-football-team']\n",
    "all_data = []\n",
    "​\n",
    "for team in teams:\n",
    "    # Visit the page\n",
    "    #url = f\"https://www.spotrac.com/nfl/{team}/cap/2020\"\n",
    "    #url = f\"https://www.spotrac.com/nfl/{team}/cap/2021\"\n",
    "    #url = f\"https://www.spotrac.com/nfl/{team}/cap/2022\"\n",
    "    \n",
    "    url = f\"https://www.spotrac.com/nfl/{team}/cap/\"\n",
    "    browser.visit(url)\n",
    "​\n",
    "    # Create BeautifulSoup object; parse with 'html.parser'\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "​\n",
    "    # Find the correct table with Active Players\n",
    "    all_tables = soup.find_all('table')\n",
    "    active_table = None\n",
    "    for table in all_tables:\n",
    "        ths = table.find_all('th')\n",
    "        for th in ths:\n",
    "            if 'Active Players' in th.text:\n",
    "                active_table = table\n",
    "                break\n",
    "        if active_table is not None:\n",
    "            break\n",
    "​\n",
    "    # Retrieve all elements that contain player salary information\n",
    "    players = active_table.find_all('tr')\n",
    "​\n",
    "    # Iterate through each player\n",
    "    for player in players:\n",
    "        # Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "        name_tag = player.find('td', class_='player')\n",
    "        if name_tag is not None:\n",
    "            a_tag = name_tag.find('a')\n",
    "            if a_tag is not None:\n",
    "                name = a_tag.text\n",
    "                # Find all td tags within the player's row\n",
    "                all_tds = player.find_all('td')\n",
    "                if len(all_tds) >= 11:  # There should be at least 11 td tags if the player row is valid\n",
    "                    position = all_tds[1].find('span').text\n",
    "                    cap_hit = all_tds[2].find('span').text.strip()\n",
    "                    base_salary = all_tds[3].find('span').text.strip()\n",
    "                    signing_bonus = all_tds[4].find('span').text.strip()\n",
    "                    roster_bonus = all_tds[5].find('span').text.strip()\n",
    "                    option_bonus = all_tds[6].find('span').text.strip()\n",
    "                    workout_bonus = all_tds[7].find('span').text.strip()\n",
    "                    restructure_bonus = all_tds[8].find('span').text.strip()\n",
    "                    incentive_bonus = all_tds[9].find('span').text.strip()\n",
    "                    cap_% = all_tds[10].find('span').text.strip()\n",
    "                    \n",
    "                    player_data = {\n",
    "                        \"team\": team,\n",
    "                        \"name\": name,\n",
    "                        \"position\": position,\n",
    "                        \"cap_hit\": cap_hit,\n",
    "                        \"base_salary\": base_salary,\n",
    "                        \"signing_bonus\": signing_bonus,\n",
    "                        \"roster_bonus\": roster_bonus,\n",
    "                        \"option_bonus\": option_bonus,\n",
    "                        \"workout_bonus\": workout_bonus,\n",
    "                        \"restructure_bonus\": restructure_bonus,\n",
    "                        \"incentive_bonus\": incentive_bonus\n",
    "                    }\n",
    "                    all_data.append(player_data)\n",
    "\n",
    "# Convert to a DataFrame and export to a csv file\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(\"nfl_salaries.csv\")\n",
    "# Close the browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c1ab3e-0f00-4f23-b926-caf62c7a6795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize browser\n",
    "browser = Browser('chrome', executable_path='C:\\\\chromedriver_win32\\\\chromedriver.exe', headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bafe6a-247b-4568-bc42-54b7a1114a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of NFL teams\n",
    "teams = ['arizona-cardinals', 'atlanta-falcons', 'baltimore-ravens', \n",
    "         'buffalo-bills', 'carolina-panthers', 'chicago-bears', \n",
    "         'cincinnati-bengals', 'cleveland-browns', 'dallas-cowboys', \n",
    "         'denver-broncos', 'detroit-lions', 'green-bay-packers', \n",
    "         'houston-texans', 'indianapolis-colts', 'jacksonville-jaguars', \n",
    "         'kansas-city-chiefs', 'las-vegas-raiders', 'los-angeles-chargers', \n",
    "         'los-angeles-rams', 'miami-dolphins', 'minnesota-vikings', \n",
    "         'new-england-patriots', 'new-orleans-saints', 'new-york-giants', \n",
    "         'new-york-jets', 'philadelphia-eagles', 'pittsburgh-steelers', \n",
    "         'san-francisco-49ers', 'seattle-seahawks', 'tampa-bay-buccaneers', \n",
    "         'tennessee-titans', 'washington-football-team']\n",
    "all_data = []\n",
    "​\n",
    "for team in teams:\n",
    "    # Visit the page\n",
    "    url = f\"https://www.spotrac.com/nfl/{team}/cap/\"\n",
    "    browser.visit(url)\n",
    "​\n",
    "    # Create BeautifulSoup object; parse with 'html.parser'\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "​\n",
    "    # Find the correct table with Active Players\n",
    "    all_tables = soup.find_all('table')\n",
    "    active_table = None\n",
    "    for table in all_tables:\n",
    "        ths = table.find_all('th')\n",
    "        for th in ths:\n",
    "            if 'Active Players' in th.text:\n",
    "                active_table = table\n",
    "                break\n",
    "        if active_table is not None:\n",
    "            break\n",
    "​\n",
    "    # Retrieve all elements that contain player salary information\n",
    "    players = active_table.find_all('tr')\n",
    "​\n",
    "    # Iterate through each player\n",
    "    for player in players:\n",
    "        # Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "        name_tag = player.find('td', class_='player')\n",
    "        if name_tag is not None:\n",
    "            a_tag = name_tag.find('a')\n",
    "            if a_tag is not None:\n",
    "                name = a_tag.text\n",
    "                # Find all td tags within the player's row\n",
    "                all_tds = player.find_all('td')\n",
    "                if len(all_tds) >= 10:  # There should be at least 10 td tags if the player row is valid\n",
    "                    position = all_tds[1].find('span').text\n",
    "                    cap_hit = all_tds[2].find('span').text.strip()\n",
    "                    base_salary = all_tds[3].find('span').text.strip()\n",
    "                    signing_bonus = all_tds[4].find('span').text.strip()\n",
    "                    roster_bonus = all_tds[5].find('span').text.strip()\n",
    "                    option_bonus = all_tds[6].find('span').text.strip()\n",
    "                    workout_bonus = all_tds[7].find('span').text.strip()\n",
    "                    restructure_bonus = all_tds[8].find('span').text.strip()\n",
    "                    incentive_bonus = all_tds[9].find('span').text.strip()\n",
    "                    \n",
    "                    player_data = {\n",
    "                        \"team\": team,\n",
    "                        \"name\": name,\n",
    "                        \"position\": position,\n",
    "                        \"cap_hit\": cap_hit,\n",
    "                        \"base_salary\": base_salary,\n",
    "                        \"signing_bonus\": signing_bonus,\n",
    "                        \"roster_bonus\": roster_bonus,\n",
    "                        \"option_bonus\": option_bonus,\n",
    "                        \"workout_bonus\": workout_bonus,\n",
    "                        \"restructure_bonus\": restructure_bonus,\n",
    "                        \"incentive_bonus\": incentive_bonus\n",
    "                    }\n",
    "                    all_data.append(player_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5073357-6581-4cf6-a136-d80da91c9598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a DataFrame and export to a csv file\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(\"nfl_salaries.csv\") # 2023\n",
    "\n",
    "#df_2020 = pd.DataFrame(all_data)\n",
    "#df_2020.to_csv(\"nfl_salaries.csv\") # 2020\n",
    "\n",
    "#df_2021 = pd.DataFrame(all_data) # 2021\n",
    "#df_2021.to_csv(\"nfl_salaries.csv\")\n",
    "\n",
    "#df_2022 = pd.DataFrame(all_data) # 2022\n",
    "#df_2022.to_csv(\"nfl_salaries.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae43b8b7-bcbe-43d9-9fca-bfb9c2fd83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
